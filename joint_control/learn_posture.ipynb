{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Posture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use machine learning to recognize robot's posture (following the example in [scikit-learn-intro.ipynb](./scikit-learn-intro.ipynb) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "We have colleceted data before, you need to add new data if you want to add new posture.\n",
    "\n",
    "* the dateset are in *robot_pose_data* folder\n",
    "* each file contains the data belongs to this posture, e.g. the data in *Back* file are collected when robot was in \"Back\" posture\n",
    "* the data file can be load by ```pickle```, e.g. ```pickle.load(open('Back'))```, the data is a list of feature data\n",
    "* the features (e.g. each row of the data) are ['AngleX', 'AngleY', 'LHipYawPitch', 'LHipRoll', 'LHipPitch', 'LKneePitch', 'RHipYawPitch', 'RHipRoll', 'RHipPitch', 'RKneePitch'], where 'AngleX' and 'AngleY' are body angle (e.g. ```Perception.imu```) and others are joint angles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['clf', 'permutation']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pickle\n",
    "from os import listdir, path\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "ROBOT_POSE_DATA_DIR = 'robot_pose_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stand', 'Left', 'Crouch', 'Sit', 'Belly', 'Knee', 'StandInit', 'Back', 'Right', 'Frog', 'HeadBack']\n"
     ]
    }
   ],
   "source": [
    "classes = listdir(ROBOT_POSE_DATA_DIR)\n",
    "print classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pose_data(i):\n",
    "    '''load pose data from file'''\n",
    "    data = []\n",
    "    target = []\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    filename = path.join(ROBOT_POSE_DATA_DIR, classes[i])\n",
    "    data = pickle.load(open(filename))\n",
    "    target = [i] * len(data)\n",
    "    print len(data), len(target)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11\n",
      "20 20\n",
      "30 30\n",
      "26 26\n",
      "10 10\n",
      "10 10\n",
      "52 52\n",
      "10 10\n",
      "11 11\n",
      "10 10\n",
      "10 10\n",
      "total number of data 200\n"
     ]
    }
   ],
   "source": [
    "# load all the data\n",
    "all_data = []\n",
    "all_target = []\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    data,target = load_pose_data(i)\n",
    "    all_data.extend(data)\n",
    "    all_target.extend(target)\n",
    "    \n",
    "    \n",
    "print 'total number of data', len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learn on training data\n",
    "\n",
    "In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T). An example of an estimator is the class sklearn.svm.SVC that implements support vector classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shuffule data\n",
    "permutation = np.random.permutation(len(all_data))\n",
    "n_training_data = int(len(all_data) * 0.5)\n",
    "training_data = permutation[:n_training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129  15  72 168  67  25 161  27  58 163 121 101 119  19  56  71 183  33\n",
      " 128 118  34 130 132 170 197 135 133 196  31 108  99 153  92 199  85   0\n",
      "  12 149  48  21  40 173  51 195  77  61 113 112  82  39 115 131 185  60\n",
      " 114 150  17 145  54 184 110  62 164 136  89  28  16  44 178 156 104   3\n",
      "   8 106 100 159 187  46 126 160 111  43 177 186   1  74 169 190  45  32\n",
      "  87  91  49 122 125   5 141 139 117  95]\n"
     ]
    }
   ],
   "source": [
    "print training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
       "  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_data = []\n",
    "fit_target = []\n",
    "for i in range(0,len(training_data)):\n",
    "    fit_data.append(all_data[training_data[i]])\n",
    "    fit_target.append(all_target[training_data[i]])\n",
    "    \n",
    "clf.fit(fit_data, fit_target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), 0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(all_data[1]), all_target[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(expected, predicted):\n",
    "    print(\"Classification report:\\n%s\\n\" % metrics.classification_report(expected, predicted))\n",
    "\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       0.93      1.00      0.96        13\n",
      "          3       1.00      1.00      1.00        17\n",
      "          4       1.00      1.00      1.00         5\n",
      "          5       1.00      1.00      1.00         5\n",
      "          6       1.00      1.00      1.00        23\n",
      "          7       1.00      1.00      1.00         4\n",
      "          8       1.00      0.83      0.91         6\n",
      "          9       1.00      1.00      1.00         5\n",
      "         10       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.99      0.99      0.99       100\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 6  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 11  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  5  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  5]]\n"
     ]
    }
   ],
   "source": [
    "expected = []\n",
    "predicted = []\n",
    "prediction_data = []\n",
    "for i in range(0,len(all_data)):\n",
    "    if( not (i in training_data)):\n",
    "        expected.append(all_target[i])\n",
    "        prediction_data.append(all_data[i])\n",
    "predicted = clf.predict(prediction_data)\n",
    "\n",
    "evaluate(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deploy to the real system\n",
    "\n",
    "We can simple use `pickle` module to serialize the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "ROBOT_POSE_CLF = 'robot_pose.pkl'\n",
    "pickle.dump(clf, open(ROBOT_POSE_CLF, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in the application we can load the trained classifier again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stand Stand\n",
      "Stand Stand\n",
      "Stand Stand\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Crouch Crouch\n",
      "Crouch Crouch\n",
      "Crouch Crouch\n",
      "Crouch Crouch\n",
      "Crouch Crouch\n",
      "Crouch Crouch\n",
      "Sit Sit\n",
      "Sit Sit\n",
      "Sit Sit\n",
      "Sit Sit\n",
      "Sit Sit\n",
      "Belly Belly\n",
      "Belly Belly\n",
      "Knee Knee\n",
      "Knee Knee\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "StandInit StandInit\n",
      "Back Back\n",
      "Back Back\n",
      "Right Right\n",
      "Right Right\n",
      "Frog Frog\n",
      "Frog Frog\n",
      "HeadBack HeadBack\n",
      "HeadBack HeadBack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "clf2 = pickle.load(open(ROBOT_POSE_CLF))\n",
    "for i in range(0,len(all_data),5):\n",
    "    print classes[clf2.predict(all_data[i])], classes[all_target[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
